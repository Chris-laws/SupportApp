llm:
  xs: tinyllama:1.1b-instruct-q8_0
  s: phi3:mini
  m: mistral:7b-instruct
  l: llama3.1:8b-instruct-q4_K_M
  xl: llama3.1:70b-instruct-q4_K_M
decoding:
  greedy:
    temperature: 0.0
    top_p: 1.0
    max_tokens: 512
  balanced:
    temperature: 0.2
    top_p: 0.9
    max_tokens: 512
  creative:
    temperature: 0.7
    top_p: 0.9
    max_tokens: 512
